{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 사용 및 랜드마크 수집을 위한 사전설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pynput.mouse import Listener\n",
    "from screeninfo import get_monitors\n",
    "# based on https://github.com/google/mediapipe/blob/master/docs/solutions/face_mesh.md\n",
    "\n",
    "def on_click(x, y, button, pressed):\n",
    "    # 마우스 클릭될 때마다 좌표와 시간, 얼굴 랜드마크를 기록하는 함수\n",
    "    monitor = get_monitors()[0]\n",
    "    if pressed and results.multi_face_landmarks:\n",
    "        records.append(\n",
    "            {\n",
    "                'coord' : (x/monitor.width, y/monitor.height),\n",
    "                'time' : time.time()-start_time,\n",
    "                'frame' : frame_count,\n",
    "                'landmark' : np.array([ [d.x, d.y, d.z] for d in results.multi_face_landmarks[0].landmark ])\n",
    "            }\n",
    "        )\n",
    "        print(f\"Mouse clicked at: {x/monitor.width}, {y/monitor.height} \\t time: {time.time()-start_time:0.2f}\")\n",
    "        # save with pickle\n",
    "        with open('records.pkl', 'wb') as f:\n",
    "            pickle.dump(records, f)\n",
    "        \n",
    "def count_captured_landmarks():\n",
    "    # 전체 landmark중 얼마나 화면에 찍히고 있는지 알려주는 함수\n",
    "    count = 0 \n",
    "    for data_point in results.multi_face_landmarks[0].landmark:\n",
    "        if (data_point.x <= 1 and data_point.x >= 0) and (data_point.y <= 1 and data_point.y >= 0):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "records = [] # 클릭 좌표를 저장할 리스트\n",
    "frame_count = 0 # 프레임 수를 저장할 변수\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "start_time = time.time()\n",
    "listener = Listener(on_click=on_click)\n",
    "listener.start()\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# 웹캠 화면이 최상단에 뜨게 하기 위한 설정\n",
    "# 최상단을 유지하려는 경우에만 주석을 해제해주세요\n",
    "# cv2.namedWindow('window', cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.setWindowProperty('window', cv2.WND_PROP_TOPMOST, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: 0.26145833333333335, 0.3074074074074074 \t time: 2.69\n",
      "Mouse clicked at: 0.28802083333333334, 0.5574074074074075 \t time: 5.47\n",
      "Mouse clicked at: 0.5567708333333333, 0.4583333333333333 \t time: 7.26\n",
      "Mouse clicked at: 0.19322916666666667, 0.6351851851851852 \t time: 9.40\n",
      "Mouse clicked at: 0.6322916666666667, 0.5777777777777777 \t time: 10.70\n",
      "Mouse clicked at: 0.10416666666666667, 0.07592592592592592 \t time: 14.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wnsdh\\Desktop\\Lab\\vision\\python-webcam-eyetracking\\track_and_record_example.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mmulti_face_landmarks:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mfor\u001b[39;00m face_landmarks \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mmulti_face_landmarks:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         mp_drawing\u001b[39m.\u001b[39;49mdraw_landmarks(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m             image\u001b[39m=\u001b[39;49mimage,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             landmark_list\u001b[39m=\u001b[39;49mface_landmarks,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             connections\u001b[39m=\u001b[39;49mmp_face_mesh\u001b[39m.\u001b[39;49mFACEMESH_TESSELATION,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             landmark_drawing_spec\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             connection_drawing_spec\u001b[39m=\u001b[39;49mmp_drawing_styles\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m             \u001b[39m.\u001b[39;49mget_default_face_mesh_tesselation_style())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             image\u001b[39m=\u001b[39mimage,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             landmark_list\u001b[39m=\u001b[39mface_landmarks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m             connection_drawing_spec\u001b[39m=\u001b[39mmp_drawing_styles\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m             \u001b[39m.\u001b[39mget_default_face_mesh_contours_style())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             image\u001b[39m=\u001b[39mimage,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m             landmark_list\u001b[39m=\u001b[39mface_landmarks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m             connection_drawing_spec\u001b[39m=\u001b[39mmp_drawing_styles\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wnsdh/Desktop/Lab/vision/python-webcam-eyetracking/track_and_record_example.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m             \u001b[39m.\u001b[39mget_default_face_mesh_iris_connections_style())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py:179\u001b[0m, in \u001b[0;36mdraw_landmarks\u001b[1;34m(image, landmark_list, connections, landmark_drawing_spec, connection_drawing_spec)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m start_idx \u001b[39min\u001b[39;00m idx_to_coordinates \u001b[39mand\u001b[39;00m end_idx \u001b[39min\u001b[39;00m idx_to_coordinates:\n\u001b[0;32m    177\u001b[0m       drawing_spec \u001b[39m=\u001b[39m connection_drawing_spec[connection] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    178\u001b[0m           connection_drawing_spec, Mapping) \u001b[39melse\u001b[39;00m connection_drawing_spec\n\u001b[1;32m--> 179\u001b[0m       cv2\u001b[39m.\u001b[39;49mline(image, idx_to_coordinates[start_idx],\n\u001b[0;32m    180\u001b[0m                idx_to_coordinates[end_idx], drawing_spec\u001b[39m.\u001b[39;49mcolor,\n\u001b[0;32m    181\u001b[0m                drawing_spec\u001b[39m.\u001b[39;49mthickness)\n\u001b[0;32m    182\u001b[0m \u001b[39m# Draws landmark points after finishing the connection lines, which is\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39m# aesthetically better.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m landmark_drawing_spec:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"웹캠을 찾을 수 없습니다.\")\n",
    "            break\n",
    "\n",
    "        image.flags.writeable = False # 성능 향상을 위해 이미지를 읽기 전용으로 만듭니다.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_iris_connections_style())\n",
    "                \n",
    "            image = cv2.flip(image, 1)\n",
    "            cv2.putText(image, f'{count_captured_landmarks()}/478', (5, 25), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "        cv2.imshow('window', image)\n",
    "        # 이미지 재생을 위한 대기시간\n",
    "        cv2.waitKey(5)\n",
    "        frame_count += 1\n",
    "        \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': (335, 191),\n",
       " 'time': 23.87341046333313,\n",
       " 'frame': 232,\n",
       " 'landmark': array([[ 0.73864388,  1.05022252, -0.02767511],\n",
       "        [ 0.7614361 ,  0.99460292, -0.06176444],\n",
       "        [ 0.75393409,  1.00860226, -0.03121721],\n",
       "        ...,\n",
       "        [ 0.80475986,  0.85804492,  0.0242392 ],\n",
       "        [ 0.79443681,  0.87345934,  0.0242392 ],\n",
       "        [ 0.80764079,  0.88528502,  0.0242392 ]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: 1919, 807 \t time: 50.86\n",
      "Mouse clicked at: 1122, 1059 \t time: 53.83\n",
      "Mouse clicked at: 420, 450 \t time: 55.26\n",
      "Mouse clicked at: 934, 206 \t time: 56.04\n",
      "Mouse clicked at: 235, 133 \t time: 56.82\n",
      "Mouse clicked at: 293, 519 \t time: 57.86\n",
      "Mouse clicked at: 1150, 573 \t time: 59.28\n",
      "Mouse clicked at: 1616, 231 \t time: 60.18\n",
      "Mouse clicked at: 884, 1079 \t time: 61.39\n",
      "Mouse clicked at: 1466, 14 \t time: 62.39\n",
      "Mouse clicked at: 394, 365 \t time: 69.21\n",
      "Mouse clicked at: 847, 429 \t time: 71.16\n",
      "Mouse clicked at: 967, 1068 \t time: 72.41\n",
      "Mouse clicked at: 387, 554 \t time: 73.52\n",
      "Mouse clicked at: 383, 640 \t time: 74.14\n",
      "Mouse clicked at: 527, 502 \t time: 74.66\n",
      "Mouse clicked at: 847, 750 \t time: 75.61\n",
      "Mouse clicked at: 643, 170 \t time: 76.34\n",
      "Mouse clicked at: 443, 0 \t time: 76.79\n",
      "Mouse clicked at: 1186, 402 \t time: 77.91\n",
      "Mouse clicked at: 1136, 1061 \t time: 79.45\n",
      "Mouse clicked at: 1131, 1062 \t time: 81.51\n",
      "Mouse clicked at: 824, 600 \t time: 97.89\n",
      "Mouse clicked at: 1138, 1054 \t time: 126.15\n",
      "Mouse clicked at: 1136, 1053 \t time: 127.61\n",
      "Mouse clicked at: 854, 1065 \t time: 129.12\n",
      "Mouse clicked at: 962, 1063 \t time: 145.70\n",
      "Mouse clicked at: 0, 714 \t time: 147.81\n",
      "Mouse clicked at: 339, 878 \t time: 148.71\n",
      "Mouse clicked at: 1919, 802 \t time: 150.50\n",
      "Mouse clicked at: 1144, 1073 \t time: 154.14\n",
      "Mouse clicked at: 1123, 1055 \t time: 154.70\n",
      "Mouse clicked at: 1137, 1053 \t time: 155.53\n",
      "Mouse clicked at: 1127, 1060 \t time: 156.67\n",
      "Mouse clicked at: 1919, 500 \t time: 157.87\n",
      "Mouse clicked at: 1203, 916 \t time: 161.46\n",
      "Mouse clicked at: 1919, 914 \t time: 162.96\n"
     ]
    }
   ],
   "source": [
    "records[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Landmark 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 478, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: 349, 714 \t time: 184.95\n",
      "Mouse clicked at: 183, 780 \t time: 186.76\n",
      "Mouse clicked at: 941, 1079 \t time: 189.79\n",
      "Mouse clicked at: 982, 527 \t time: 190.83\n",
      "Mouse clicked at: 982, 527 \t time: 190.97\n",
      "Mouse clicked at: 525, 176 \t time: 191.99\n",
      "Mouse clicked at: 521, 161 \t time: 192.46\n",
      "Mouse clicked at: 913, 1066 \t time: 195.86\n",
      "Mouse clicked at: 1312, 4 \t time: 196.61\n",
      "Mouse clicked at: 838, 0 \t time: 197.00\n",
      "Mouse clicked at: 828, 0 \t time: 197.36\n",
      "Mouse clicked at: 823, 5 \t time: 197.95\n",
      "Mouse clicked at: 573, 0 \t time: 198.99\n",
      "Mouse clicked at: 558, 46 \t time: 199.30\n",
      "Mouse clicked at: 345, 605 \t time: 205.92\n",
      "Mouse clicked at: 1079, 1068 \t time: 210.10\n",
      "Mouse clicked at: 800, 532 \t time: 210.64\n",
      "Mouse clicked at: 495, 184 \t time: 211.55\n",
      "Mouse clicked at: 769, 372 \t time: 215.49\n",
      "Mouse clicked at: 1087, 1055 \t time: 217.67\n",
      "Mouse clicked at: 1091, 1051 \t time: 218.88\n",
      "Mouse clicked at: 1060, 1060 \t time: 219.82\n",
      "Mouse clicked at: 1010, 1057 \t time: 220.31\n",
      "Mouse clicked at: 199, 908 \t time: 222.17\n"
     ]
    }
   ],
   "source": [
    "landmarks = [ r['landmark'] for r in records ]\n",
    "landmarks = np.array(landmarks)\n",
    "print(landmarks.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
